# Plant-Image-Classification
In this project we aimed to classify species of plants, which are divided into categories according to the species of the plant to which they belong. Being a classification problem, given an image, the goal is to predict the correct class label.


### 1. Data exploration and Visualization: 

First, in this work, we analyzed data provided for the challenge based on the two following aspects: RGB statistical distribution and class distribution. Regarding the first analysis, we understood all channel distributions are approximately the same. Thus, we could not extract any specific information from each channel. Performing the second analysis, we found out two main issues, one was that we had an imbalance dataset due to the sizes of class “species 1” and “species 6” (with 186 and 222 images, respectively). Another problem was that in total the amount data was quite low, since deep learning approaches always involves with a large number of parameters, that need to be tuned (trained) so having appropriate amount of data is crucial, otherwise our model will be overfitted on the training data and it cannot be generalized well during the test time that affects the final prediction. Our approach for coping with these challenges was to benefit from Data Augmentation techniques (to increase the size of our dataset) and Transfer Learning (to improve the ability of generalization of our model).

### 2. Data Splitting: 

During experiments, in the first phase, for selecting appropriate models and hyperparameter tuning, since the number of submissions were limited, we were required test and fine tune our model locally and then submit the best obtained results, in this regard and to have more unbiased estimate of the challenge test set, we divided the dataset into 3 parts, 20% of data were considered as the test set, and the rest of data were divided into 80% and 20% for training and validation, respectively. The training data used for training the model. The hyperparameter tuning procedure was done using the validation data, and finally the best obtained results were considered for testing on the local test set. However, after selecting the best model and tuning the hyperparameters, in the second phase, we divided the whole data into two parts: training and validation in which we considered 90% images as the training and the rest (10%) as the validation set. Because in this way we were training on more samples and the model can generalize better on the test set of the challenge. For credibility of our experiments and accurate tuning of the models, in the first phase of our experiments we defined a seed for the random function which allows reproducibility of the results. This is how we could fully observe the effect of hyperparameters on the models and compare them after we tuned them.
